<html>
<head>
<title>CS 289A:  Machine Learning Project</title>
</head>

<body bgcolor='ffffff'>

<a href="index.html"><font size=6 color='009000'>
CS 289A:  Machine Learning</font></a>
<font size=4 color='009000'>(Spring 2021)</font><br>
<font size=6 color='009000'>
Project
</font>


<h3 style="background-color:#009000;color:#ffffff;padding:1px">&nbsp;</h3>


<p>
<b>20% of final grade.</b>
The project should be done in <b>teams of 2&ndash;3 students</b>.
Please find a partner.
</p>

<p>
Please discuss your ideas with one of the Project Teaching Assistants
<b>before</b> submitting your initial proposal.
Sign up your group for a ten-minute meeting slot with one of them on
<a href="https://docs.google.com/spreadsheets/d/1nGLZ7ioUwQa9eUp-5JPPVnDfsCi4nbn2NRzKW_yN3T8/edit">this
Google spreadsheet</a> <b>before 11:59 PM on April 4</b>.
The Project TAs, and their areas of expertise, are:
</p>

<p>
Deirdre Quillen
<a href="mailto:dequillen@gmail.com"><tt>dequillen@gmail.com</tt></a>:
using machine learning to predict wildfire spread and risk, and
to forecast other weather variables;
reinforcement learning; robotic manipulation.
<br>
Yaodong Yu <a href="mailto:yaodong_yu@berkeley.edu"><tt>yaodong_yu@berkeley.edu</tt></a>:
robust machine learning, optimization for machine learning,
empirical/theoretical understanding of deep learning.
<br>
Zhuang Liu
<a href="mailto:zhuangl@berkeley.edu"><tt>zhuangl@berkeley.edu</tt></a>:
neural networks and computer vision related problems.
</p>


<h3 style="background-color:#900000;color:#ffffff;padding:1px">Deliverables</h3>

<ul>
<li>  Initial proposal, due <b>Friday, April 9</b></li>
<li>  Project video (maximum 3 minutes), due <b>Saturday, May 8</b>,
      50% of score</li>
<li>  Final report (maximum 8 pages), due <b>Sunday, May 9</b>,
      50% of score</li>
</ul>


<h3 style="background-color:#900000;color:#ffffff;padding:1px">Overview</h3>

<p>
The project theme may be anything related to machine learning techniques
discussed in class, including
<ul>
<li>  critically revisiting a published paper (including reproducing
      the experiments, generating new graphs and visual representations, and
      discussing the results);
</li>
<li>  writing a literature review in a specific domain
      (e.g., adversarial examples, transfer learning, active learning,
      meta-learning) and making a critical comparison
      (ideally on a standard benchmark dataset);
</li>
<li>  conducting original theoretical research (e.g., attack one of the COLT
      open problems:
      <a href="http://jmlr.org/proceedings/papers/v35/">2014</a>,
      <a href="http://jmlr.org/proceedings/papers/v40/">2015</a>);
</li>
<li>  conducting original practical research by applying
      machine learning methods to a public or private dataset
      (see project ideas below).
</li>
</ul>
</p>

<p>
You are welcome and encouraged to design a project that
is related to your research outside this course.
However, please be honorable and don't suggest a project that
you've <i>already</i> completed as part of your research.
</p>


<h3 style="background-color:#900000;color:#ffffff;padding:1px">Initial
proposal</h3>


<p>
The initial proposal is primarily a proposal, and need not be long.
Write a few paragraphs describing what you have decided to do.
You may have any number of figures and references.
<ul>
<li>  Include background information:  What is the application domain or
      field of research?  Why is the problem important?
      What specific questions will you try to answer?
</li>
<li>  Talk about what data sources you plan to use, including
      the number(s) of samples and number(s) of features.
      If it's visual data, include an illustration if possible.
</li>
<li>  Explain what methods you are planning to use and why.
</li>
<li>  If you have done preliminary work, explain what you have already done
      (e.g., downloaded and played with data, tried <i>k</i>-nearest neighbors,
      did a mock-up of the user interface, etc.).
</li>
<li>  What will be the core of the work for your project?
      (That is, how do you expect to spend most of your time?)
      Do you expect to be judged primarily on your writing, your programming,
      your exhaustive exploration of methods and data, something else, or
      some combination thereof?
      (You are welcome to use any and all libraries and codes written by
      others, but you should be clear on what your substantial new
      contribution will be.)
</li>
<li>  The initial proposal is not graded.  Its purpose is to make sure
      you start early and we give you feedback on your idea. 
</li>
<li>  Please submit the initial proposal (like the final) through Gradescope.
</li>
</ul>
</p>


<h3 style="background-color:#900000;color:#ffffff;padding:1px">Video</h3>


<ul>
<li>  The video should be clear and understandable, describing everything
      you think is important about your project
      (motivation, description, techniques, results, etc.).
</li>
<li>  The video needs to be self-contained:  any CS 289A student should
      be able to understand what you did (at least at a high level)
      without consulting any other materials.
</li>
<li>  You can make the video as simple as slides with a voice overlay, or
      as fancy as you want.
</li>
<li>  As long as it is clear and understandable, you will not be graded on
      the fanciness of the video.  Content is what will matter.
      (Fanciness might be fun, though.)
</li>
<li>  You must upload the video on YouTube and provide us with the link.
      You may choose to keep the video private (i.e., only those with
      the link can view it), in which case only the instructors will view it.
      You can make the video public if you want to.
</li>
<li>  <b>Important:</b>
      The video can be at most 3 minutes long.
      This is a very strict requirement;
      a video of length 3 minutes and 1 second does not count.
      The length is counted as whatever YouTube says it is.
      In case you are worried about how you will fit an entire class project
      into three minutes, take a look at
<a href="https://www.youtube.com/results?search_query=3+minute+thesis">these
      videos</a>, which fit an entire Ph.D. thesis into three minutes.
</li>
</ul>


<h3 style="background-color:#900000;color:#ffffff;padding:1px">Final
report</h3>


<ul>
<li>  We encourage you to use a template from
      your favorite machine learning conference (e.g.,
<a href="https://nips.cc/Conferences/2018/PaperInformation/StyleFiles">NIPS</a>
or <a href="https://www.icml.cc/Conferences/2019/StyleAuthorInstructions">ICML</a>).
</li>
<li>  There is no minimum length requirement.  The maximum length is 8 pages.
</li>
<li>  The submission must be made through Gradescope.
      Any one person from the group can submit the proposal.
      Please include the full names, student IDs, and email addresses for
      all the members of the group.
</li>
<li>  Also, for inspiration, here are some of
      <a href="http://cs231n.stanford.edu/reports.html">the final projects from
      a Neural Networks class at Stanford</a>.
      It is a truth universally acknowledged that
      your work will be better than Stanford's.
</li>
</ul>


<h3 style="background-color:#900000;color:#ffffff;padding:1px">Grading
criteria</h3>


<p>
The video and the final report will be graded with 5 criteria.
<ul>
<li>  Relevance:  should be related to machine learning techniques.
</li>
<li>  Usefulness:  should answer good questions or
      solve problems worth solving.
      (The questions should be clearly stated in the proposal.)
</li>
<li>  Soundness:  choose data sets with enough examples to get
      statistically significant results;
      conduct sound numerical experiments
      (split the data into training/validation/test sets);
      make comparative result tables using validation or cross-validation;
      use the test set only for final assessment;
      include error bars if appropriate;
      add graphs and other good means of visualization
      (e.g., projections onto principal components);
      provide sound proofs;
      if you choose a literature review, mention the most important papers in
      the area and give proper credit.
</li>
<li>  Clarity/presentation:  good paper organization, good bibliography,
      enough graphs and visual support, length should not exceed 8 pages.
</li>
<li>  Novelty/originality:  we do not require novelty/originality, but
      it could add a few points.
</li>
</ul>
</p>


<h3 style="background-color:#900000;color:#ffffff;padding:1px">Project
ideas</h3>


<p>
The ideas in this list fall mainly under the fourth category,
practical research.
If you prefer to revisit an important paper, simply pick a paper.
If you prefer to conduct a literature review,
simply pick a machine learning topic that interests you.
If you prefer to conduct theoretical research, you'd better already know
what you're doing.
</p>

<ul>
<li> Try your hand at the distribution shift challenge <a href="https://wilds.stanford.edu"WILDS</a>. Can you improve upon the basic ERM framework by leveraging diverse datasets?
</li>

<li> The method of <a href="https://arxiv.org/pdf/1703.01365.pdf">integrated gradients</a> is an attribution technique that attempts to attribute some fraction of the decision made by a neural network to individual features of the input. Implement integrated gradients and briefly evaluate it.</li>

<li> Businesses love to promote themselves on Yelp, leaving false positive reviews. With <a href="https://www.yelp.com/dataset_challenge/">this dataset</a>, predict which reviews are likely to have been written by the business itself.</li>

<li> Browsers typically download files to the Downloads folder (or another fixed, set folder). Develop a method for automatically placing files in the appropriate folder. You can constrain yourself to text documents, or to images.</li>

<li> Image captioning using RNN/LSTM is also an important topic. Try to generate meaningful text from images/videos. For example, take a look at the <a href="http://mscoco.org/dataset/#captions-challenge2015"> COCO Captioning Challenge</a>.</li>

<li>Can you train a fine-grained image classifier? There are many specialized datasets, like this one for dog breeds. This can be applied with the project above or in isolation. Architectures? See <a href="http://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf">this paper</a>.</li>

<li>Reinforcement Learning tackles sequential decision-making problems where the only information about the system is received through interaction. A great resource to understand RL algorithms is <a href="https://spinningup.openai.com/en/latest/">Spinning Up</a>. Pick your favorite algorithm from there and apply it to more complex simulated environment (e.g., <a href="http://mujoco.org">MuJoCo</a> is free for students).</li>

<li>If you want harder problems, involving various aspects of ML, you can also check this: <a href="https://openai.com/blog/requests-for-research-2/">OpenAI Requests for Research</a></li>

<li>Fake news 1. Can you train a system to decide if two articles are related and agree? The <a href="http://www.fakenewschallenge.org/">Fake News Challenge</a> gives access to a dataset for this. You can propose your own solution and see if you get close to the winners!</li>

<li>Fake news 2. Can you classify articles by bias and factuality? <a href="https://arxiv.org/abs/1810.01765">There is a dataset (and SVM algorithm) </a> built with this purpose. Their code is also available, therefore a substantial innovation should be attempted.</li>

<li>Can you fool a classifier with a real object? There are works that make traffic signs classification systems (trained on the <a href="http://cvrr.ucsd.edu/LISA/lisa-traffic-sign-dataset.html">LISA dataset</a>) predict that a stop sign is a <a href="https://arxiv.org/pdf/1707.08945.pdf">45mph speed limit</a> sign. Or that a <a href="https://www.csail.mit.edu/news/fooling-neural-networks-w3d-printed-objects">3D printed turtle is a rifle.</a></li>

<li>Can you visualize the features learned by a Deep Neural Network? When training Deep Neural Networks, the hidden state at each layer can be understood as features or representations useful to perform the desired task. One such tool is guided backpropagation, and more recently other dataset-wide visualizations have been proposed. See <a href="https://distill.pub/2017/feature-visualization/"> this blog post</a>.</li>

<li>Dependently typed programming languages, such as Idris, provide safety guarantees that are not available in the more mainstream languages. Can any of these features be used to improve the data analytic stack, or developer ergonomics?</li>

<li>Try your hand at a computer vision challenge with one of these <a href="https://github.com/chrieke/awesome-satellite-imagery-datasets">satellite image datasets</a>.  Can you predict building footprints, segment out roads, or even generate a map from a satellite image? </li>

<li>Ever wish you could read someone's mind?  <a href="https://openneuro.org/public/datasets">OpenNeuro</a> hosts a variety of fMRI, EEG, ECoG, etc. data. </li>

<li>Can you transcribe music directly from audio files?  <a href="https://homes.cs.washington.edu/~thickstn/musicnet.html">MusicNet</a> provides a curated collection of labeled classical music. 
</li>

<li>
Can you predict if the blocks in the picture will fall?  Can you estimate the cohesiveness of two particles by the way they interact?  Build a simple simulator or use the training set <a href="https://intphys.com/benchmark/training_set.html">here</a> to explore <a href="https://medium.com/syncedreview/mits-josh-tenenbaum-on-intuitive-physics-psychology-in-ai-99690db3480">Intuitive Physics</a>.
</li>

<li>
The price of Bitcoin has been erratically rising and falling over the past couple of years.  Can you build a model to predict the price of Bitcoin?  Try your hand at <a href="https://www.kaggle.com/team-ai/bitcoin-price-prediction/version/1">this dataset</a>.
</li>

<li>
Can you predict a person&rsquo;s Myers&ndash;Briggs personality type from the content they post on social media?  <a href="https://www.kaggle.com/datasnaek/mbti-type">This dataset</a> makes for a fun challenge.
</li>

<li>
Can you identify questions that have the same intent?  Try out <a href="https://www.kaggle.com/c/quora-question-pairs/data">this dataset</a> of questions posted on Quora.
</li>

<li>
Can you identify the genre of a song from its spectrogram or other audio features?  <a href="https://github.com/mdeff/fma">This dataset</a> provides labeled audio tracks for classification.
</li>

</ul>

<p>
Other useful data sources:
<ul>
<li>  <a href="http://kaggle.com/">Kaggle</a></li>
<li>  <a href="http://codalab.org">CodaLab</a></li>
<li>  <a href="http://www.image-net.org/">ImageNet</a></li>
<li>  <a href="http://mscoco.org/"> Microsoft COCO</a></li>
<li>  <a href="http://webscope.sandbox.yahoo.com/">Yahoo Webscope</a></li>
<li>  <a href="http://www.cvlibs.net/datasets/kitti/">KITTI Vision Benchmark
      Suite</a></li>
</ul>
</p>


<h3 style="background-color:#009000;color:#ffffff;padding:1px">&nbsp;</h3>


<address>
<a href="https://people.eecs.berkeley.edu/~jrs/"><img src="../sig.gif" width=151 height=21></a>
</address>
</body>
</html>
